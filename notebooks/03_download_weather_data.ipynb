{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import gzip\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import botocore\n",
    "\n",
    "# Set up the S3 client without credentials (for public datasets)\n",
    "s3 = boto3.client('s3', region_name='us-east-1',\n",
    "                 config=boto3.session.Config(signature_version=botocore.UNSIGNED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 selected stations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION_ID</th>\n",
       "      <th>STATION NAME</th>\n",
       "      <th>CITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>744860-94789</td>\n",
       "      <td>JOHN F KENNEDY INTERNATIONAL AIRPORT</td>\n",
       "      <td>New York City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>722950-23174</td>\n",
       "      <td>LOS ANGELES INTERNATIONAL AIRPORT</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>725300-94846</td>\n",
       "      <td>CHICAGO O'HARE INTERNATIONAL AIRPORT</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>722020-12839</td>\n",
       "      <td>MIAMI INTERNATIONAL AIRPORT</td>\n",
       "      <td>Miami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>722430-12960</td>\n",
       "      <td>G BUSH INTERCONTINENTAL AP/HOUSTON AP</td>\n",
       "      <td>Houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>725090-14739</td>\n",
       "      <td>GEN E L LOGAN INTERNATIONAL AIRPORT</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>726580-14922</td>\n",
       "      <td>MINNEAPOLIS-ST PAUL INTERNATIONAL AP</td>\n",
       "      <td>Minneapolis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>727930-24233</td>\n",
       "      <td>SEATTLE-TACOMA INTERNATIONAL AIRPORT</td>\n",
       "      <td>Seattle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     STATION_ID                           STATION NAME           CITY\n",
       "0  744860-94789   JOHN F KENNEDY INTERNATIONAL AIRPORT  New York City\n",
       "1  722950-23174      LOS ANGELES INTERNATIONAL AIRPORT    Los Angeles\n",
       "2  725300-94846   CHICAGO O'HARE INTERNATIONAL AIRPORT        Chicago\n",
       "3  722020-12839            MIAMI INTERNATIONAL AIRPORT          Miami\n",
       "4  722430-12960  G BUSH INTERCONTINENTAL AP/HOUSTON AP        Houston\n",
       "5  725090-14739    GEN E L LOGAN INTERNATIONAL AIRPORT         Boston\n",
       "6  726580-14922   MINNEAPOLIS-ST PAUL INTERNATIONAL AP    Minneapolis\n",
       "7  727930-24233   SEATTLE-TACOMA INTERNATIONAL AIRPORT        Seattle"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the bucket name\n",
    "bucket_name = 'noaa-isd-pds'\n",
    "\n",
    "# Load the selected stations\n",
    "selected_stations_df = pd.read_csv('../data/processed/selected_stations.csv')\n",
    "print(f\"Loaded {len(selected_stations_df)} selected stations\")\n",
    "display(selected_stations_df[['STATION_ID', 'STATION NAME', 'CITY']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will download data for years: [2019, 2020, 2021, 2022, 2023, 2024]\n"
     ]
    }
   ],
   "source": [
    "# Define the years we want to download\n",
    "years = list(range(2019, 2025))  # 2019 through 2024 \n",
    "print(f\"Will download data for years: {years}\")\n",
    "\n",
    "# Create the download directory\n",
    "download_dir = '../data/raw/isd_data'\n",
    "os.makedirs(download_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a file exists in S3\n",
    "def check_file_exists(s3_key):\n",
    "    \"\"\"Check if a file exists in the S3 bucket\"\"\"\n",
    "    try:\n",
    "        s3.head_object(Bucket=bucket_name, Key=s3_key)\n",
    "        return True\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == '404':\n",
    "            return False\n",
    "        else:\n",
    "            # Something else went wrong\n",
    "            print(f\"Error checking {s3_key}: {str(e)}\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download a specific station and year\n",
    "def download_station_year(station_id, year):\n",
    "    \"\"\"Download weather data for a specific station and year from AWS S3\"\"\"\n",
    "    # Format: data/2023/010010-99999-2023.gz\n",
    "    filename = f\"{station_id}-{year}.gz\"\n",
    "    s3_key = f\"data/{year}/{filename}\"\n",
    "    local_path = os.path.join(download_dir, filename)\n",
    "    \n",
    "    # Skip if file already exists locally\n",
    "    if os.path.exists(local_path):\n",
    "        return f\"Skipped existing file: {filename}\"\n",
    "    \n",
    "    # Check if the file exists in S3\n",
    "    if not check_file_exists(s3_key):\n",
    "        return f\"File not found in S3: {s3_key}\"\n",
    "    \n",
    "    try:\n",
    "        s3.download_file(Bucket=bucket_name, Key=s3_key, Filename=local_path)\n",
    "        \n",
    "        # Verify the download\n",
    "        if os.path.exists(local_path) and os.path.getsize(local_path) > 0:\n",
    "            # Attempt to open the file to confirm it's valid\n",
    "            try:\n",
    "                with gzip.open(local_path, 'rb') as f:\n",
    "                    # Read a small sample to verify it's a valid gzip file\n",
    "                    sample = f.read(100)\n",
    "                return f\"Downloaded: {filename} ({os.path.getsize(local_path)/1024:.1f} KB)\"\n",
    "            except Exception as e:\n",
    "                # If we can't open the file, it might be corrupted\n",
    "                os.remove(local_path)\n",
    "                return f\"Downloaded corrupted file {filename}: {str(e)}\"\n",
    "        else:\n",
    "            return f\"Downloaded empty file: {filename}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error downloading {filename}: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking which files exist in S3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking years: 100%|██████████| 6/6 [00:00<00:00,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2019: 8/8 stations available\n",
      "Year 2020: 8/8 stations available\n",
      "Year 2021: 8/8 stations available\n",
      "Year 2022: 8/8 stations available\n",
      "Year 2023: 8/8 stations available\n",
      "Year 2024: 8/8 stations available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# First, check which files already exist in S3\n",
    "print(\"Checking which files exist in S3...\")\n",
    "available_files = {}\n",
    "\n",
    "for year in tqdm(years, desc=\"Checking years\"):\n",
    "    available_files[year] = []\n",
    "    for _, station in selected_stations_df.iterrows():\n",
    "        station_id = station['STATION_ID']\n",
    "        s3_key = f\"data/{year}/{station_id}-{year}.gz\"\n",
    "        if check_file_exists(s3_key):\n",
    "            available_files[year].append(station_id)\n",
    "\n",
    "# Display available files by year\n",
    "for year in years:\n",
    "    print(f\"Year {year}: {len(available_files[year])}/{len(selected_stations_df)} stations available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download of 48 files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:05<00:00,  9.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# Download files sequentially with progress tracking\n",
    "download_tasks = []\n",
    "for _, station in selected_stations_df.iterrows():\n",
    "    station_id = station['STATION_ID']\n",
    "    for year in years:\n",
    "        if station_id in available_files[year]:\n",
    "            download_tasks.append((station_id, year))\n",
    "\n",
    "print(f\"Starting download of {len(download_tasks)} files...\")\n",
    "results = []\n",
    "\n",
    "with tqdm(total=len(download_tasks)) as pbar:\n",
    "    for station_id, year in download_tasks:\n",
    "        result = download_station_year(station_id, year)\n",
    "        results.append(result)\n",
    "        pbar.update(1)\n",
    "        # Small delay to avoid hammering the S3 bucket\n",
    "        time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Download summary:\n",
      "- Successfully downloaded: 0 files\n",
      "- Skipped existing files: 48 files\n",
      "- Files not found in S3: 0 files\n",
      "- Download errors: 0 files\n"
     ]
    }
   ],
   "source": [
    "# Count successes and failures\n",
    "downloads = sum(1 for r in results if r.startswith(\"Downloaded\"))\n",
    "skipped = sum(1 for r in results if r.startswith(\"Skipped\"))\n",
    "not_found = sum(1 for r in results if r.startswith(\"File not found\"))\n",
    "errors = sum(1 for r in results if r.startswith(\"Error\"))\n",
    "\n",
    "print(f\"\\nDownload summary:\")\n",
    "print(f\"- Successfully downloaded: {downloads} files\")\n",
    "print(f\"- Skipped existing files: {skipped} files\")\n",
    "print(f\"- Files not found in S3: {not_found} files\")\n",
    "print(f\"- Download errors: {errors} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total files in download directory: 48\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# List the downloaded files\n",
    "downloaded_files = glob.glob(os.path.join(download_dir, \"*.gz\"))\n",
    "print(f\"\\nTotal files in download directory: {len(downloaded_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of downloaded files:\n",
      "722020-12839-2019.gz - 861.7 KB\n",
      "722020-12839-2020.gz - 900.4 KB\n",
      "722020-12839-2021.gz - 850.1 KB\n",
      "722020-12839-2022.gz - 861.8 KB\n",
      "722020-12839-2023.gz - 830.7 KB\n",
      "\n",
      "Total size of downloaded files: 39.86 MB\n",
      "Average file size: 850.42 KB\n",
      "Largest file: 1056.97 KB\n",
      "Smallest file: 665.31 KB\n"
     ]
    }
   ],
   "source": [
    "# Display a sample of downloaded files\n",
    "if downloaded_files:\n",
    "    print(\"\\nSample of downloaded files:\")\n",
    "    for file in sorted(downloaded_files)[:5]:\n",
    "        print(f\"{os.path.basename(file)} - {os.path.getsize(file)/1024:.1f} KB\")\n",
    "        \n",
    "    # Get file sizes\n",
    "    file_sizes = [os.path.getsize(file) / 1024 for file in downloaded_files]  # KB\n",
    "    \n",
    "    print(f\"\\nTotal size of downloaded files: {sum(file_sizes)/1024:.2f} MB\")\n",
    "    print(f\"Average file size: {sum(file_sizes)/len(file_sizes):.2f} KB\")\n",
    "    print(f\"Largest file: {max(file_sizes):.2f} KB\")\n",
    "    print(f\"Smallest file: {min(file_sizes):.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data availability by city:\n",
      "Chicago: 6 files\n",
      "Houston: 6 files\n",
      "Seattle: 6 files\n",
      "Minneapolis: 6 files\n",
      "Los Angeles: 6 files\n",
      "New York City: 6 files\n",
      "Miami: 6 files\n",
      "Boston: 6 files\n"
     ]
    }
   ],
   "source": [
    "# Verify all cities have at least some data\n",
    "city_data = {}\n",
    "for file in downloaded_files:\n",
    "    for _, row in selected_stations_df.iterrows():\n",
    "        if row['STATION_ID'] in os.path.basename(file):\n",
    "            city = row['CITY']\n",
    "            if city not in city_data:\n",
    "                city_data[city] = []\n",
    "            city_data[city].append(file)\n",
    "\n",
    "print(\"\\nData availability by city:\")\n",
    "for city, files in city_data.items():\n",
    "    print(f\"{city}: {len(files)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved download report to ../data/processed/download_report.csv\n"
     ]
    }
   ],
   "source": [
    "# Save a report of downloaded files\n",
    "download_report = pd.DataFrame(results, columns=['Status'])\n",
    "download_report.to_csv('../data/processed/download_report.csv', index=False)\n",
    "print(f\"Saved download report to ../data/processed/download_report.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
